"""
V√©rifier si le checkpoint attend des coordonn√©es normalis√©es ou pas
On va tester les deux cas et voir lequel donne val_loss ‚âà 0.356
"""
import torch
import numpy as np
import sys
sys.path.insert(0, 'src')

print("="*80)
print("üîç TEST: Le checkpoint attend-il lat2d/lon2d NORMALIS√âS?")
print("="*80)

from model_multipollutants import MultiPollutantLightningModule
import yaml

# Load config
with open('configs/config_all_pollutants.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Create Lightning module
print("\n1Ô∏è‚É£ Creating model and loading checkpoint...")
lightning_module = MultiPollutantLightningModule(config=config)
ckpt_path = "logs/multipollutants_climax_ddp/version_47/checkpoints/best-val_loss_val_loss=0.3557-step_step=311.ckpt"
lightning_module._checkpoint_path_to_load = ckpt_path
lightning_module.setup(stage='fit')
lightning_module.eval()

# Get one validation batch
print("\n2Ô∏è‚É£ Loading validation data...")
from datamodule_fixed import AQNetDataModule
config['data']['num_workers'] = 0
data_module = AQNetDataModule(config)
data_module.setup('fit')
val_loader = data_module.val_dataloader()

# Get first batch
x, y, lead_times = next(iter(val_loader))
print(f"   Batch shape: x={x.shape}, y={y.shape}")

variables = tuple(config['data']['variables'])
lat_idx = variables.index('lat2d')
lon_idx = variables.index('lon2d')

print(f"\n3Ô∏è‚É£ Current data statistics:")
print(f"   lat2d (index {lat_idx}): mean={x[:, lat_idx].mean():.4f}, std={x[:, lat_idx].std():.4f}")
print(f"   lon2d (index {lon_idx}): mean={x[:, lon_idx].mean():.4f}, std={x[:, lon_idx].std():.4f}")

# TEST 1: With current data (coordinates NOT normalized)
print(f"\n4Ô∏è‚É£ TEST 1: Avec coordonn√©es NON-NORMALIS√âES (actuelles)")
with torch.no_grad():
    y_pred = lightning_module.model(x, lead_times, variables)
    china_mask = lightning_module.china_mask.to(dtype=torch.bool).unsqueeze(0).unsqueeze(0)
    loss_1 = lightning_module._masked_mse(y_pred, y, china_mask)
print(f"   Loss: {loss_1.item():.4f}")

# TEST 2: Normalize lat2d and lon2d manually
print(f"\n5Ô∏è‚É£ TEST 2: Avec coordonn√©es NORMALIS√âES")
x_normalized = x.clone()

# Normalize lat2d: (lat - 32.0) / 12.0
x_normalized[:, lat_idx] = (x[:, lat_idx] - 32.0) / 12.0

# Normalize lon2d: (lon - 106.0) / 16.0
x_normalized[:, lon_idx] = (x[:, lon_idx] - 106.0) / 16.0

print(f"   lat2d apr√®s normalisation: mean={x_normalized[:, lat_idx].mean():.4f}, std={x_normalized[:, lat_idx].std():.4f}")
print(f"   lon2d apr√®s normalisation: mean={x_normalized[:, lon_idx].mean():.4f}, std={x_normalized[:, lon_idx].std():.4f}")

with torch.no_grad():
    y_pred_2 = lightning_module.model(x_normalized, lead_times, variables)
    loss_2 = lightning_module._masked_mse(y_pred_2, y, china_mask)
print(f"   Loss: {loss_2.item():.4f}")

# Compare
print(f"\n" + "="*80)
print(f"R√âSULTATS:")
print(f"="*80)
print(f"Loss sans normalisation des coordonn√©es:  {loss_1.item():.4f}")
print(f"Loss avec normalisation des coordonn√©es:  {loss_2.item():.4f}")
print(f"Loss attendu du checkpoint:               0.3557")
print(f"")

if abs(loss_1.item() - 0.3557) < abs(loss_2.item() - 0.3557):
    print(f"‚úÖ CONCLUSION: Le checkpoint attend des coordonn√©es NON-NORMALIS√âES!")
    print(f"   Diff√©rence: {abs(loss_1.item() - 0.3557):.4f}")
    print(f"   ACTION: Garder le dataloader actuel (pas de normalisation de lat2d/lon2d)")
elif abs(loss_2.item() - 0.3557) < abs(loss_1.item() - 0.3557):
    print(f"‚úÖ CONCLUSION: Le checkpoint attend des coordonn√©es NORMALIS√âES!")
    print(f"   Diff√©rence: {abs(loss_2.item() - 0.3557):.4f}")
    print(f"   ACTION: Modifier le dataloader pour normaliser lat2d/lon2d")
else:
    print(f"‚ùå PROBL√àME: Aucun des deux ne donne 0.3557!")
    print(f"   Il y a un autre bug dans le mod√®le ou les donn√©es")

print(f"="*80)
