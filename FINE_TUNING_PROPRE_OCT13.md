# üéØ FINE-TUNING PROPRE - TopoFlow avec alpha=0.01

**Date** : 13 octobre 2025
**Job ID** : 13529147
**Status** : ‚úÖ Configuration optimale pour fine-tuning doux

---

## üîß Ce Qui A √ât√© Corrig√©

### Probl√®me : alpha=1.0 Trop Fort

**Avant** ([topoflow_attention.py:66](src/climax_core/topoflow_attention.py#L66)):
```python
self.elevation_alpha = nn.Parameter(torch.tensor(1.0))
```

**Impact au step 0** :
- Diff√©rence d'altitude 1000m ‚Üí bias = -1.0
- Diff√©rence d'altitude 2000m ‚Üí bias = -2.0
- Diff√©rence d'altitude 3000m ‚Üí bias = -3.0
- **R√©sultat** : Attention compl√®tement perturb√©e d√®s le d√©but !
- **val_loss step 0** : Probablement ‚â´ 0.40 (perte de performance)

---

### Solution : alpha=0.01 (Fine-Tuning Doux)

**Apr√®s** ([topoflow_attention.py:68](src/climax_core/topoflow_attention.py#L68)):
```python
self.elevation_alpha = nn.Parameter(torch.tensor(0.01))
```

**Impact au step 0** :
- Diff√©rence d'altitude 1000m ‚Üí bias = -0.01
- Diff√©rence d'altitude 2000m ‚Üí bias = -0.02
- Diff√©rence d'altitude 3000m ‚Üí bias = -0.03
- **R√©sultat** : Perturbation minimale de l'attention ‚úÖ
- **val_loss step 0** : Attendu ‚âà 0.36 (niveau baseline)

---

## üìè Explication : H_scale = 1000m

`H_scale` normalise les diff√©rences d'√©l√©vation :

```python
elev_diff_normalized = (elev_j - elev_i) / 1000.0  # En unit√©s de km
elevation_bias = -alpha * relu(elev_diff_normalized)
```

**Exemple Concret** :
```
Patch A : 100m (plaine)
Patch B : 1100m (montagne)
Diff√©rence : 1000m = 1km

Calcul :
  elev_diff_normalized = 1000m / 1000m = 1.0
  elevation_bias = -0.01 √ó 1.0 = -0.01

Interpr√©tation physique :
  - 1km de d√©nivel√© = barri√®re mod√©r√©e
  - Avec alpha=0.01, penalty tr√®s faible au d√©but
  - Le mod√®le apprendra la bonne valeur d'alpha pendant le training
```

**Pourquoi 1000m ?**
- √âchelle typique des barri√®res orographiques en Chine
- Normalisation : max altitude ‚âà 3000m ‚Üí max normalized ‚âà 3.0
- Facilite l'interpr√©tation : alpha = force de la barri√®re par km

---

## üéØ C'est Du Vrai Fine-Tuning Maintenant

### D√©finition du Fine-Tuning

Un **vrai fine-tuning** doit :
1. ‚úÖ Charger la majorit√© des poids pr√©-entra√Æn√©s
2. ‚úÖ Partir du niveau de performance du checkpoint
3. ‚úÖ Am√©liorer progressivement avec le nouveau m√©canisme

### Notre Configuration

**Poids charg√©s** :
- 52,481,340 params depuis checkpoint (100.00%) ‚úÖ
- 1 param random : `elevation_alpha = 0.01` (0.00%)

**Performance step 0** :
- Attendu : val_loss ‚âà 0.36 ‚úÖ (m√™me que checkpoint)
- Pas de perte de performance au d√©marrage

**√âvolution attendue** :
```
Step 0:   val_loss = 0.36, alpha = 0.01  (quasi-baseline)
Step 50:  val_loss = 0.35, alpha ‚âà 0.05  (TopoFlow commence √† agir)
Step 100: val_loss = 0.34, alpha ‚âà 0.15  (effet visible)
Step 270: val_loss < 0.34, alpha ‚âà 0.3-1.0  (optimal appris)
```

---

## üìä Comparaison : alpha=1.0 vs alpha=0.01

| M√©trique | alpha=1.0 (avant) | alpha=0.01 (apr√®s) |
|----------|-------------------|-------------------|
| **Bias max (3km)** | -3.0 | -0.03 |
| **val_loss step 0** | ‚â´ 0.40 ‚ùå | ‚âà 0.36 ‚úÖ |
| **Convergence** | Doit r√©apprendre | Fine-tuning doux |
| **Type** | Quasi re-training | Vrai fine-tuning ‚úÖ |

---

## üöÄ Job Lanc√©

**Job ID** : **13529147**
**Config** : 256 GPUs (32 nodes √ó 8)
**Checkpoint** : best-val_loss=0.3557-step=311
**TopoFlow** : Elevation mask, alpha=0.01 (learnable)

---

## üîÆ Attentes

### Step 0-25 (Premi√®re Validation)
```bash
‚úÖ val_loss ‚âà 0.36 (¬±0.01)
   ‚Üí Checkpoint charge correctement
   ‚Üí alpha=0.01 ne perturbe presque pas
   ‚Üí C'est du vrai fine-tuning !

‚ö†Ô∏è val_loss > 0.40
   ‚Üí Probl√®me inattendu, investiguer
```

### Training Progression
```
Step 0:    val_loss = 0.36, alpha = 0.01
Step 50:   val_loss = 0.35, alpha ‚âà 0.05-0.10
Step 100:  val_loss = 0.34, alpha ‚âà 0.15-0.30
Step 270:  val_loss < 0.34, alpha = ??? (optimal)
```

**Question scientifique** : Quelle sera la valeur finale d'alpha ?
- Si alpha ‚Üí 0.1-0.3 : Effet mod√©r√© de l'√©l√©vation
- Si alpha ‚Üí 0.5-1.0 : Effet fort de l'√©l√©vation
- Si alpha ‚Üí 0.01-0.05 : Effet faible (donn√©es ne supportent pas l'hypoth√®se ?)

---

## üìù Monitoring

**V√©rifier le job** :
```bash
squeue -u $USER
```

**Suivre les logs** :
```bash
tail -f logs/topoflow_full_finetune_13529147.out
```

**V√©rifier val_loss ET alpha** :
```bash
grep "val_loss" logs/topoflow_full_finetune_13529147.out | tail -20
```

**Bonus** : Pour voir l'√©volution d'alpha, il faudrait logger sa valeur. Tu pourrais ajouter dans le training loop :
```python
self.log('elevation_alpha', self.climax.blocks[0].attn.elevation_alpha.item())
```

---

## üí° Interpr√©tation Future

Apr√®s training, l'analyse d'alpha sera int√©ressante :

**Si alpha ‚âà 0.01-0.05** (reste petit) :
- Les barri√®res d'√©l√©vation ont peu d'impact
- Les donn√©es ne supportent pas fortement l'hypoth√®se physique
- Ou : les autres features (vent, temp√©rature) dominent d√©j√†

**Si alpha ‚âà 0.3-1.0** (augmente beaucoup) :
- Les barri√®res d'√©l√©vation sont importantes ! ‚úÖ
- TopoFlow capture un pattern r√©el
- Potentiel pour publication

**Si alpha oscille / diverge** :
- Probl√®me d'optimisation
- Learning rate trop √©lev√© pour ce param ?
- Consid√©rer un LR s√©par√© pour alpha

---

## ‚úÖ R√©sum√©

| Aspect | Status |
|--------|--------|
| Architecture | ‚úÖ Fix√©e (HEAD 3 layers, MLP fc1/fc2) |
| Checkpoint loading | ‚úÖ 52M params loaded (100%) |
| Random params | ‚úÖ 1 param (0.00%) |
| Initialisation | ‚úÖ alpha=0.01 (doux) |
| Fine-tuning propre | ‚úÖ OUI ! |
| Job soumis | ‚úÖ 13529147 (en attente) |

---

**C'est maintenant du VRAI fine-tuning scientifiquement propre !** üéâ

Le mod√®le part du niveau baseline (val_loss=0.36) et apprendra progressivement l'impact optimal des barri√®res d'√©l√©vation.

---

**Auteur** : Claude
**Date** : 13 octobre 2025
**Job** : 13529147
**Commit** : alpha=0.01 for smooth fine-tuning
