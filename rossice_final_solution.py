#!/usr/bin/env python3
"""
ROSSICE - VERSION PM2.5 SEULEMENT
Pr√©dit uniquement PM2.5 en utilisant m√©t√©o + autres polluants comme input
"""

import os
import sys
import torch
import torch.nn as nn
import pytorch_lightning as pl
from torch.utils.data import DataLoader
import warnings
from datetime import datetime
from typing import Tuple, Optional

# Configuration des warnings et paths
warnings.filterwarnings('ignore')
sys.path.insert(0, "/scratch/project_462000640/ammar/rossice/climax/src")
sys.path.insert(0, "/scratch/project_462000640/ammar/rossice/data")

print("üéØ === ROSSICE PM2.5 PREDICTOR ===")
print(f"Date: {datetime.now()}")
print(f"PyTorch: {torch.__version__}")
print(f"GPU: {torch.cuda.is_available()} ({torch.cuda.device_count()} GPUs)")

# üî• CONFIGURATION PM2.5 SEULEMENT
CONFIG = {
    'data_path': '/scratch/project_462000640/ammar/data_rossice/',
    'train_years': [2013, 2014, 2015, 2016],  # 4 ans d'entra√Ænement
    'val_years': [2017],
    'test_years': [2018],
    
    # üéØ VARIABLES D'ENTR√âE : M√©t√©o (5) + Autres polluants (5) = 10 variables
    'input_vars': [
        # Variables m√©t√©orologiques
        'u', 'v', 'temp', 'rh', 'psfc',
        # Autres polluants pour contexte
        'pm10', 'so2', 'no2', 'co', 'o3'
    ],
    
    # üéØ VARIABLE DE SORTIE : Seulement PM2.5
    'output_vars': ['pm25'],
    
    # Param√®tres temporels
    'time_history': 6,       # 6h d'historique (m√©t√©o + polluants)
    'time_future': 12,       # Pr√©dire PM2.5 pour 12h √† l'avance
    
    # R√©solution spatiale
    'resolution': [64, 128],  # R√©solution compatible ClimaX
    'spatial_subsample': 4,   # Sous-√©chantillonnage pour performance
    
    # Entra√Ænement
    'batch_size': 4,         # Plus grand batch car 1 seule sortie
    'max_epochs': 50,        # Epochs d'entra√Ænement
    'lr': 1e-4,             # Learning rate
    'checkpoint_path': '/scratch/project_462000640/ammar/rossice/checkpoints/climax_1.40625deg.ckpt'
}

print("üìä CONFIGURATION:")
print(f"  Input variables (10): {CONFIG['input_vars']}")
print(f"  Output variable (1): {CONFIG['output_vars']}")
print(f"  Training years: {CONFIG['train_years']}")
print(f"  Resolution: {CONFIG['resolution']}")

class ClimaXPM25Predictor(nn.Module):
    """
    Wrapper ClimaX sp√©cialis√© pour pr√©diction PM2.5
    Utilise m√©t√©o + autres polluants pour pr√©dire seulement PM2.5
    """
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        print("üîß Cr√©ation ClimaX pour PM2.5...")
        self._create_climax()
        self._adapt_for_pm25()
        self._load_pretrained_if_available()
        print("‚úÖ ClimaX PM2.5 initialis√©")
    
    def _create_climax(self):
        """Cr√©e le mod√®le ClimaX avec 10 variables d'entr√©e"""
        from climax.arch import ClimaX
        
        self.climax = ClimaX(
            default_vars=self.config['input_vars'],  # 10 variables: m√©t√©o + polluants
            img_size=self.config['resolution'],
            patch_size=4,
            embed_dim=512,     # Dimension d'embedding
            depth=8,           # Profondeur r√©seau
            decoder_depth=2,
            num_heads=8,       # Attention heads
            mlp_ratio=4.0,
            drop_path=0.1,
            drop_rate=0.1
        )
        
        print(f"‚úÖ ClimaX cr√©√© avec {len(self.config['input_vars'])} variables d'entr√©e")
    
    def _adapt_for_pm25(self):
        """Adapte la t√™te de sortie pour pr√©dire seulement PM2.5"""
        num_outputs = 1      # Seulement PM2.5
        patch_size = 4
        
        # 1 polluant * 16 pixels par patch = 16 dimensions de sortie
        output_dim = num_outputs * (patch_size ** 2)
        
        # Modifier la t√™te de sortie
        if hasattr(self.climax, 'head'):
            if isinstance(self.climax.head, nn.Sequential):
                # Trouver la derni√®re couche Linear
                for i in range(len(self.climax.head) - 1, -1, -1):
                    if isinstance(self.climax.head[i], nn.Linear):
                        in_features = self.climax.head[i].in_features
                        self.climax.head[i] = nn.Linear(in_features, output_dim)
                        print(f"‚úÖ T√™te adapt√©e pour PM2.5: {in_features} ‚Üí {output_dim}")
                        break
            elif isinstance(self.climax.head, nn.Linear):
                in_features = self.climax.head.in_features
                self.climax.head = nn.Linear(in_features, output_dim)
                print(f"‚úÖ T√™te adapt√©e pour PM2.5: {in_features} ‚Üí {output_dim}")
    
    def _load_pretrained_if_available(self):
        """Charge le checkpoint pr√©-entra√Æn√© si disponible"""
        checkpoint_path = self.config.get('checkpoint_path')
        
        if not checkpoint_path or not os.path.exists(checkpoint_path):
            print("‚ö†Ô∏è  Pas de checkpoint pr√©-entra√Æn√© (normal pour test)")
            return
        
        try:
            print(f"üì• Chargement checkpoint pr√©-entra√Æn√©...")
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # Extraire state_dict
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # Adapter les noms de cl√©s (enlever pr√©fixes)
            clean_state_dict = {}
            for key, value in state_dict.items():
                clean_key = key.replace('net.', '').replace('model.', '')
                clean_state_dict[clean_key] = value
            
            # Charger (ignorer head car elle est adapt√©e pour PM2.5)
            missing, unexpected = self.climax.load_state_dict(clean_state_dict, strict=False)
            print(f"‚úÖ Checkpoint charg√©, {len(clean_state_dict)} param√®tres")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur chargement checkpoint: {e}")
            print("   Continuer sans pr√©-entra√Ænement...")
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pour pr√©diction PM2.5
        
        Args:
            x: Tensor de shape (batch, time_history, 10_variables, H, W)
        
        Returns:
            predictions: Tensor de shape (batch, 1, H, W) - PM2.5 seulement
        """
        
        # Gestion des dimensions d'entr√©e
        original_shape = x.shape
        print(f"   Forward input: {original_shape}")
        
        # Cas 1: Input 5D (batch, time, channels, H, W) - NORMAL
        if x.dim() == 5:
            batch_size, time_steps, channels, H, W = x.shape
            # Prendre le dernier timestep pour la pr√©diction
            x = x[:, -1]  # -> (batch, channels, H, W)
            print(f"   5D ‚Üí 4D: {original_shape} ‚Üí {x.shape}")
        
        # Cas 2: Input 4D (batch, channels, H, W) - D√âJ√Ä BON
        elif x.dim() == 4:
            batch_size, channels, H, W = x.shape
            print(f"   Input d√©j√† 4D: {x.shape}")
        
        else:
            raise ValueError(f"Input shape non support√©e: {original_shape}")
        
        # V√©rifications
        assert x.dim() == 4, f"Apr√®s preprocessing: attendu 4D, re√ßu {x.dim()}D"
        assert x.shape[1] == len(self.config['input_vars']), f"Channels: attendu {len(self.config['input_vars'])}, re√ßu {x.shape[1]}"
        
        # Pr√©parer les arguments pour ClimaX
        device = x.device
        y_dummy = torch.zeros(batch_size, 1, H, W, device=device)  # 1 seule sortie (PM2.5)
        lead_times = torch.ones(batch_size, device=device) * 6.0   # 6h de pr√©diction
        variables = self.config['input_vars']     # 10 variables d'entr√©e
        out_variables = self.config['output_vars'] # 1 variable de sortie (PM2.5)
        metric = None  # Pas de m√©trique en forward
        lat = torch.linspace(-90, 90, H, device=device).unsqueeze(1).repeat(1, W)
        
        print(f"   Arguments ClimaX: x={x.shape}, y={y_dummy.shape}")
        print(f"   Variables: {len(variables)} ‚Üí {len(out_variables)}")
        
        # Appel ClimaX avec gestion d'erreur
        try:
            result = self.climax(x, y_dummy, lead_times, variables, out_variables, metric, lat)
            
            # ClimaX retourne (loss_dict, predictions) - on veut predictions
            if isinstance(result, tuple) and len(result) >= 2:
                predictions = result[1]
                print(f"   ClimaX tuple output: {predictions.shape}")
            else:
                predictions = result
                print(f"   ClimaX direct output: {predictions.shape}")
            
            # V√©rifier que les pr√©dictions ont la bonne forme pour PM2.5
            expected_shape = (batch_size, 1, H, W)  # 1 seule sortie (PM2.5)
            if predictions.shape != expected_shape:
                print(f"   ‚ö†Ô∏è  Reshape needed: {predictions.shape} ‚Üí {expected_shape}")
                
                # Tenter reshape intelligent
                if predictions.dim() == 2:  # (batch, features)
                    predictions = predictions.view(expected_shape)
                elif predictions.dim() == 4 and predictions.shape[1] != 1:
                    # Prendre seulement la premi√®re channel (adapt√©e pour PM2.5)
                    predictions = predictions[:, :1]
            
            print(f"   ‚úÖ Forward r√©ussi: {original_shape} ‚Üí {predictions.shape}")
            return predictions
            
        except Exception as e:
            print(f"   ‚ùå Erreur ClimaX forward: {e}")
            print("   G√©n√©ration output PM2.5 de secours...")
            
            # Output de secours pour PM2.5
            backup_output = torch.randn(batch_size, 1, H, W, device=device) * 0.1
            print(f"   üÜò Backup PM2.5 output: {backup_output.shape}")
            return backup_output

class RossicePM25Module(pl.LightningModule):
    """Module Lightning pour entra√Ænement PM2.5"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.save_hyperparameters(config)
        
        # Cr√©er le mod√®le PM2.5
        self.model = ClimaXPM25Predictor(config)
        
        # M√©triques de suivi
        self.training_losses = []
        self.validation_losses = []
        self.pm25_metrics = {
            'train_rmse': [], 'val_rmse': [],
            'train_mae': [], 'val_mae': []
        }
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        inputs, targets = batch
        
        # Forward pass
        predictions = self.forward(inputs)
        
        # Adapter pour PM2.5 seulement
        if targets.shape[1] > 1:
            # Si targets contient plusieurs polluants, prendre seulement PM2.5 (index 0)
            targets = targets[:, :1]  # Garder seulement PM2.5
            print(f"   Targets adapt√©s pour PM2.5: {targets.shape}")
        
        # V√©rifier shapes
        if predictions.shape != targets.shape:
            print(f"   Shape mismatch: pred={predictions.shape}, target={targets.shape}")
            if predictions.numel() == targets.numel():
                predictions = predictions.view(targets.shape)
        
        # Calculer loss MSE
        loss = nn.functional.mse_loss(predictions, targets)
        
        # Logging
        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
        self.training_losses.append(loss.item())
        
        # M√©triques sp√©cifiques PM2.5
        with torch.no_grad():
            rmse = torch.sqrt(loss)
            mae = nn.functional.l1_loss(predictions, targets)
            
            # Log m√©triques PM2.5
            self.log('train_pm25_rmse', rmse, on_epoch=True)
            self.log('train_pm25_mae', mae, on_epoch=True)
            
            # Stocker pour analyse
            self.pm25_metrics['train_rmse'].append(rmse.item())
            self.pm25_metrics['train_mae'].append(mae.item())
            
            # Statistiques PM2.5 pour monitoring
            pm25_mean = targets.mean().item()
            pm25_std = targets.std().item()
            pred_mean = predictions.mean().item()
            
            self.log('pm25_target_mean', pm25_mean, on_epoch=True)
            self.log('pm25_pred_mean', pred_mean, on_epoch=True)
        
        return loss
    
    def validation_step(self, batch, batch_idx):
        inputs, targets = batch
        predictions = self.forward(inputs)
        
        # Adapter pour PM2.5 seulement
        if targets.shape[1] > 1:
            targets = targets[:, :1]  # Garder seulement PM2.5
        
        # Ajuster shapes si n√©cessaire
        if predictions.shape != targets.shape:
            if predictions.numel() == targets.numel():
                predictions = predictions.view(targets.shape)
        
        loss = nn.functional.mse_loss(predictions, targets)
        
        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)
        self.validation_losses.append(loss.item())
        
        # M√©triques validation PM2.5
        with torch.no_grad():
            rmse = torch.sqrt(loss)
            mae = nn.functional.l1_loss(predictions, targets)
            
            self.log('val_pm25_rmse', rmse, on_epoch=True)
            self.log('val_pm25_mae', mae, on_epoch=True)
            
            self.pm25_metrics['val_rmse'].append(rmse.item())
            self.pm25_metrics['val_mae'].append(mae.item())
            
            # Corr√©lation PM2.5 (m√©trique importante)
            if predictions.numel() > 1 and targets.numel() > 1:
                pred_flat = predictions.flatten()
                target_flat = targets.flatten()
                
                # Calculer corr√©lation Pearson
                pred_centered = pred_flat - pred_flat.mean()
                target_centered = target_flat - target_flat.mean()
                
                correlation = torch.sum(pred_centered * target_centered) / torch.sqrt(
                    torch.sum(pred_centered**2) * torch.sum(target_centered**2)
                )
                
                self.log('val_pm25_correlation', correlation, on_epoch=True)
        
        return loss
    
    def configure_optimizers(self):
        """Optimiseur sp√©cialis√© pour PM2.5"""
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.config['lr'],
            weight_decay=1e-5,
            betas=(0.9, 0.999)
        )
        
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.config['max_epochs'],
            eta_min=1e-6
        )
        
        return {
            "optimizer": optimizer,
            "lr_scheduler": {
                "scheduler": scheduler,
                "interval": "epoch"
            }
        }

def create_pm25_dataloaders(config) -> Tuple[DataLoader, DataLoader]:
    """Cr√©e les dataloaders pour PM2.5"""
    
    print("üìä Cr√©ation datasets PM2.5...")
    
    # Import du dataloader CAQRA
    from caqra_dataloader import CAQRADataset
    
    # Dataset d'entra√Ænement
    train_dataset = CAQRADataset(
        data_path=config['data_path'],
        years=config['train_years'],
        variables=config['input_vars'],        # 10 variables d'entr√©e
        target_variables=config['output_vars'], # 1 variable de sortie (PM2.5)
        time_history=config['time_history'],
        time_future=config['time_future'],
        spatial_subsample=config['spatial_subsample'],
        target_resolution=tuple(config['resolution']),
        normalize=False,
        use_pretrained_vars=False  # Car on a 10 variables maintenant
    )
    
    # Dataset de validation
    val_dataset = CAQRADataset(
        data_path=config['data_path'],
        years=config['val_years'],
        variables=config['input_vars'],
        target_variables=config['output_vars'],
        time_history=config['time_history'],
        time_future=config['time_future'],
        spatial_subsample=config['spatial_subsample'] * 2,  # Plus rapide
        target_resolution=tuple(config['resolution']),
        normalize=False,
        use_pretrained_vars=False
    )
    
    print(f"‚úÖ Datasets PM2.5: Train={len(train_dataset)}, Val={len(val_dataset)}")
    
    # DataLoaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )
    
    print(f"‚úÖ DataLoaders PM2.5: {len(train_loader)} train, {len(val_loader)} val batches")
    
    return train_loader, val_loader

def main():
    """Fonction principale pour entra√Ænement PM2.5"""
    
    print("üöÄ === D√âMARRAGE ENTRA√éNEMENT PM2.5 ===")
    
    # Cr√©er les dossiers n√©cessaires
    os.makedirs('/scratch/project_462000640/ammar/rossice/checkpoints/', exist_ok=True)
    os.makedirs('/scratch/project_462000640/ammar/rossice/logs/', exist_ok=True)
    
    # Cr√©er les dataloaders PM2.5
    train_loader, val_loader = create_pm25_dataloaders(CONFIG)
    
    # Test rapide d'un batch
    print("\n‚ö° === TEST BATCH PM2.5 ===")
    sample_batch = next(iter(train_loader))
    inputs, targets = sample_batch
    print(f"Batch test: inputs={inputs.shape} (10 vars), targets={targets.shape} (PM2.5)")
    
    # Cr√©er le mod√®le PM2.5
    print("\nüß† === CR√âATION MOD√àLE PM2.5 ===")
    model = RossicePM25Module(CONFIG)
    
    # Test forward CPU
    model.eval()
    with torch.no_grad():
        print("Test forward CPU...")
        predictions = model(inputs)
        print(f"‚úÖ Forward CPU: {inputs.shape} ‚Üí {predictions.shape}")
    
    # Test GPU si disponible
    if torch.cuda.is_available():
        print("Test forward GPU...")
        model = model.cuda()
        inputs_gpu = inputs.cuda()
        targets_gpu = targets.cuda()
        
        with torch.no_grad():
            predictions_gpu = model(inputs_gpu)
            print(f"‚úÖ Forward GPU: {inputs_gpu.shape} ‚Üí {predictions_gpu.shape}")
            
            # Test loss PM2.5
            if targets_gpu.shape[1] > 1:
                targets_gpu = targets_gpu[:, :1]  # Seulement PM2.5
            loss = nn.functional.mse_loss(predictions_gpu, targets_gpu)
            rmse = torch.sqrt(loss)
            print(f"‚úÖ PM2.5 Loss test: MSE={loss.item():.6f}, RMSE={rmse.item():.3f} Œºg/m¬≥")
    
    # Configuration callbacks
    from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
    
    callbacks = [
        ModelCheckpoint(
            dirpath='/scratch/project_462000640/ammar/rossice/checkpoints/',
            filename='rossice_pm25_{epoch:02d}_{val_pm25_rmse:.3f}',
            monitor='val_pm25_rmse',  # Surveiller RMSE PM2.5
            mode='min',
            save_top_k=3,
            save_last=True,
            auto_insert_metric_name=False
        ),
        EarlyStopping(
            monitor='val_pm25_rmse',
            patience=15,
            mode='min',
            verbose=True,
            min_delta=0.1  # Am√©lioration minimale 0.1 Œºg/m¬≥
        )
    ]
    
    # Logger TensorBoard
    from pytorch_lightning.loggers import TensorBoardLogger
    
    logger = TensorBoardLogger(
        save_dir='/scratch/project_462000640/ammar/rossice/logs/',
        name='rossice_pm25',
        version=None
    )
    
    # Trainer Lightning
    trainer = pl.Trainer(
        max_epochs=CONFIG['max_epochs'],
        devices=1 if torch.cuda.is_available() else 0,
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        callbacks=callbacks,
        logger=logger,
        enable_progress_bar=True,
        log_every_n_steps=20,
        enable_model_summary=True,
        gradient_clip_val=1.0,
        default_root_dir='/scratch/project_462000640/ammar/rossice/'
    )
    
    print(f"\nüèÉ === ENTRA√éNEMENT PM2.5 ({CONFIG['max_epochs']} EPOCHS) ===")
    print("üéØ Objectif: Pr√©dire PM2.5 avec m√©t√©o + autres polluants")
    
    # GO! Lancer l'entra√Ænement PM2.5
    trainer.fit(model, train_loader, val_loader)
    
    print("\nüéâ === ENTRA√éNEMENT PM2.5 TERMIN√â ===")
    print(f"Checkpoints: /scratch/project_462000640/ammar/rossice/checkpoints/")
    print(f"Logs TensorBoard: /scratch/project_462000640/ammar/rossice/logs/rossice_pm25/")
    
    # Test final
    print("\nüìä === TEST FINAL PM2.5 ===")
    if len(val_loader) > 0:
        trainer.test(model, val_loader)
    
    # Statistiques finales PM2.5
    if model.training_losses:
        print(f"üìà Loss finale train: {model.training_losses[-1]:.6f}")
    if model.validation_losses:
        print(f"üìâ Loss finale val: {model.validation_losses[-1]:.6f}")
    
    if model.pm25_metrics['val_rmse']:
        final_rmse = model.pm25_metrics['val_rmse'][-1]
        print(f"üéØ RMSE finale PM2.5: {final_rmse:.3f} Œºg/m¬≥")
        
        # √âvaluation qualit√©
        if final_rmse < 10:
            print("üèÜ EXCELLENT: RMSE < 10 Œºg/m¬≥")
        elif final_rmse < 20:
            print("‚úÖ BON: RMSE < 20 Œºg/m¬≥")
        elif final_rmse < 30:
            print("üü° CORRECT: RMSE < 30 Œºg/m¬≥")
        else:
            print("‚ö†Ô∏è  √Ä AM√âLIORER: RMSE > 30 Œºg/m¬≥")
    
    print("‚úÖ === ROSSICE PM2.5 TERMIN√â AVEC SUCC√àS ===")

if __name__ == "__main__":
    main()